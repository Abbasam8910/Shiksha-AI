<p align="center">
  <h1 align="center">ğŸ“š Mobileshiksha</h1>
  <p align="center">
    <strong>Offline AI Tutor for Android</strong><br>
    A privacy-first educational assistant powered by on-device LLM inference
  </p>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Flutter-3.22+-blue?logo=flutter" alt="Flutter">
  <img src="https://img.shields.io/badge/Dart-3.4+-0175C2?logo=dart" alt="Dart">
  <img src="https://img.shields.io/badge/Platform-Android-green?logo=android" alt="Platform">
  <img src="https://img.shields.io/badge/License-MIT-yellow" alt="License">
</p>

---

## âœ¨ Features

- **100% Offline** â€” No internet required after initial model download
- **Privacy-First** â€” All inference happens locally; your data never leaves the device
- **Device-Aware** â€” Automatically adapts to your phone's RAM and battery level
- **Real-Time Streaming** â€” Token-by-token response generation with live UI updates
- **Markdown Support** â€” AI responses render with formatting, lists, and code blocks
- **Persistent History** â€” Chat sessions saved locally with automatic smart titles

---

## ğŸ“± Screenshots

> *Coming soon*

---

## ğŸš€ Getting Started

### Prerequisites

- [Flutter SDK](https://docs.flutter.dev/get-started/install) 3.22 or higher
- Android device or emulator (API 21+)
- ~2GB free storage for the model file

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/shiksha_v1.git
   cd shiksha_v1
   ```

2. **Install dependencies**
   ```bash
   flutter pub get
   ```

3. **Run on device**
   ```bash
   flutter run
   ```

4. **Download the model**  
   On first launch, the app will prompt you to download the quantized LLM (~1.5GB).

---

## ğŸ—ï¸ Architecture

```
lib/
â”œâ”€â”€ main.dart              # Entry point, native library loading
â”œâ”€â”€ models/                # Data models (ChatMessage, ChatSession)
â”œâ”€â”€ providers/             # Riverpod state management
â”œâ”€â”€ screens/               # UI screens (Chat, Onboarding, Download)
â””â”€â”€ services/              # Business logic
    â”œâ”€â”€ llm_service.dart           # LLM inference engine
    â”œâ”€â”€ device_config_service.dart # Hardware profiling
    â””â”€â”€ model_download_service.dart
```

### Key Components

| Component | Description |
|-----------|-------------|
| `LLMService` | Manages model loading, token streaming, and context |
| `DeviceConfigService` | Profiles RAM/battery and selects optimal config |
| `ChatProvider` | State management for messages and sessions |

---

## âš™ï¸ Device Tiers

The app automatically selects configuration based on available resources:

| Tier | RAM | Context Size | Max Tokens | Mode |
|------|-----|--------------|------------|------|
| Efficiency | < 5 GB | 2048 | 256 | CPU Only |
| Balanced | 5â€“7 GB | 2048 | 384 | CPU Only |
| Performance | â‰¥ 7 GB | 4096 | 512 | GPU Accelerated |

> Battery protection: If battery < 20%, the app forces Efficiency mode.

---

## ğŸ› ï¸ Tech Stack

- **Framework**: [Flutter](https://flutter.dev) + [Dart](https://dart.dev)
- **State Management**: [Riverpod](https://riverpod.dev)
- **Local Storage**: [Hive](https://docs.hivedb.dev)
- **LLM Engine**: [llama.cpp](https://github.com/ggerganov/llama.cpp) via `llama_cpp_dart`
- **Model**: Qwen 4-bit quantized (LoRA fine-tuned)

---

## ğŸ“– Documentation

- [Project Overview](./docs/overview.md) â€” Architecture, state diagrams, and flows

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting a PR.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [llama.cpp](https://github.com/ggerganov/llama.cpp) for efficient LLM inference
- [Flutter](https://flutter.dev) for the cross-platform framework
- The open-source community for inspiration and support

---

